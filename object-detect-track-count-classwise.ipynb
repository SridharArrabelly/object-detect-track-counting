{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1422ca8",
   "metadata": {},
   "source": [
    "#### 1. Real-time object counting and tracking using BotSort algorithm\n",
    "\n",
    "1. detect and track objects in a video\n",
    "2. put (tracker)/ a circle in the centre of each detected object\n",
    "3. put a line on the frame to count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d762aac3",
   "metadata": {},
   "source": [
    "#### 1.1 import required modules and load the YOLO11 large model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3f42499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('yolo11l.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e6bcda",
   "metadata": {},
   "source": [
    "#### 1.2 load the class names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5188ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list = model.names \n",
    "class_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536101d",
   "metadata": {},
   "source": [
    "#### 1.3 load the video file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb91b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully opened the video file 'test_videos/4.mp4'.\n"
     ]
    }
   ],
   "source": [
    "video_path = 'test_videos/4.mp4'\n",
    "\n",
    "# Check if the file exists and is not empty\n",
    "if not os.path.exists(video_path) or os.path.getsize(video_path) == 0:\n",
    "    print(f\"Error: The file '{video_path}' does not exist or is empty.\")\n",
    "else:\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Unable to open the video file '{video_path}'.\")\n",
    "    else:\n",
    "        print(f\"Successfully opened the video file '{video_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b5d8cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video_path = 'test_videos/output.avi'\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, \n",
    "                                        cv2.CAP_PROP_FRAME_HEIGHT, \n",
    "                                        cv2.CAP_PROP_FPS))\n",
    "video_writer = cv2.VideoWriter(output_video_path, \n",
    "                                cv2.VideoWriter_fourcc(*\"mp4v\"), \n",
    "                                fps, (w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d723b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 persons, 10 cars, 3 motorcycles, 851.6ms\n",
      "Speed: 2.9ms preprocess, 851.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 10 cars, 3 motorcycles, 343.1ms\n",
      "Speed: 3.4ms preprocess, 343.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 10 cars, 3 motorcycles, 343.2ms\n",
      "Speed: 1.4ms preprocess, 343.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 10 cars, 3 motorcycles, 520.3ms\n",
      "Speed: 1.4ms preprocess, 520.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 10 cars, 4 motorcycles, 673.0ms\n",
      "Speed: 1.7ms preprocess, 673.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 10 cars, 4 motorcycles, 735.3ms\n",
      "Speed: 3.9ms preprocess, 735.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 9 cars, 4 motorcycles, 548.8ms\n",
      "Speed: 2.2ms preprocess, 548.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 9 cars, 4 motorcycles, 617.4ms\n",
      "Speed: 1.4ms preprocess, 617.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 9 cars, 3 motorcycles, 545.2ms\n",
      "Speed: 3.8ms preprocess, 545.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 10 cars, 3 motorcycles, 552.2ms\n",
      "Speed: 1.5ms preprocess, 552.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 10 cars, 4 motorcycles, 594.7ms\n",
      "Speed: 2.2ms preprocess, 594.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 10 cars, 3 motorcycles, 647.6ms\n",
      "Speed: 2.0ms preprocess, 647.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 11 cars, 5 motorcycles, 564.6ms\n",
      "Speed: 1.3ms preprocess, 564.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 11 cars, 5 motorcycles, 635.2ms\n",
      "Speed: 11.1ms preprocess, 635.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 11 cars, 5 motorcycles, 387.1ms\n",
      "Speed: 2.2ms preprocess, 387.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 11 cars, 6 motorcycles, 576.6ms\n",
      "Speed: 3.0ms preprocess, 576.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 11 cars, 5 motorcycles, 581.5ms\n",
      "Speed: 3.6ms preprocess, 581.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 11 cars, 6 motorcycles, 774.3ms\n",
      "Speed: 1.5ms preprocess, 774.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 11 cars, 7 motorcycles, 671.8ms\n",
      "Speed: 1.8ms preprocess, 671.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 11 cars, 7 motorcycles, 551.5ms\n",
      "Speed: 2.7ms preprocess, 551.5ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 11 cars, 4 motorcycles, 710.0ms\n",
      "Speed: 4.1ms preprocess, 710.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 10 cars, 7 motorcycles, 725.7ms\n",
      "Speed: 1.6ms preprocess, 725.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 10 cars, 7 motorcycles, 680.1ms\n",
      "Speed: 5.6ms preprocess, 680.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 10 cars, 5 motorcycles, 507.9ms\n",
      "Speed: 3.6ms preprocess, 507.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 10 cars, 6 motorcycles, 510.8ms\n",
      "Speed: 2.7ms preprocess, 510.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 10 cars, 6 motorcycles, 456.9ms\n",
      "Speed: 1.9ms preprocess, 456.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 10 cars, 5 motorcycles, 326.8ms\n",
      "Speed: 1.4ms preprocess, 326.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 9 cars, 5 motorcycles, 339.5ms\n",
      "Speed: 1.5ms preprocess, 339.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 9 cars, 5 motorcycles, 286.5ms\n",
      "Speed: 1.4ms preprocess, 286.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 9 cars, 5 motorcycles, 357.8ms\n",
      "Speed: 1.8ms preprocess, 357.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 9 cars, 5 motorcycles, 319.1ms\n",
      "Speed: 1.7ms preprocess, 319.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 9 cars, 4 motorcycles, 307.6ms\n",
      "Speed: 1.5ms preprocess, 307.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 9 cars, 6 motorcycles, 329.9ms\n",
      "Speed: 1.4ms preprocess, 329.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "line_y_red = 430 # line position\n",
    "\n",
    "# Dictionary to store object counts by class\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "# Dictionary to keep track of object IDs that have crossed the line\n",
    "crossed_ids = set()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Run YOLO tracking on the frame\n",
    "    results = model.track(frame, persist=True, classes=[0, 2, 3]) #, conf=0.5, iou=0.5, device='mps', show=True) # class_ids=[0, 1, 2, 3, 4, 5] for coco dataset\n",
    "    # print(results)\n",
    "\n",
    "        # Ensure results are not empty\n",
    "    if results[0].boxes.data is not None:\n",
    "        # Get the detected boxes, their class indices, and track IDs\n",
    "        boxes = results[0].boxes.xyxy.cpu()\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "        class_indices = results[0].boxes.cls.int().cpu().tolist()\n",
    "        confidences = results[0].boxes.conf.cpu()\n",
    "\n",
    "        cv2.line(frame, (690, line_y_red), (1130, line_y_red), (0, 0, 255), 2)  # Draw the red line on the frame\n",
    "        # cv2.putText(frame, 'Red Line', (690, line_y_red - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "     # Loop through each detected object\n",
    "        for box, track_id, class_idx, conf in zip(boxes, track_ids, class_indices, confidences):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            # calculate the centre point of the bounding box\n",
    "            cx = int((x1 + x2) / 2)\n",
    "            cy = int((y1 + y2) / 2)\n",
    "            \n",
    "            class_name = class_list[class_idx]  # Get the class name from the index\n",
    "            cv2.circle(frame, (cx, cy), 3, (0, 0, 255), -1)  # Draw the center point\n",
    "            cv2.putText(frame, f\"ID: {track_id} {class_name}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) \n",
    "\n",
    "            # Check if the object has crossed the red line\n",
    "            if cy > line_y_red and track_id not in crossed_ids:\n",
    "                # Mark the object as crossed\n",
    "                crossed_ids.add(track_id)\n",
    "                class_counts[class_name] += 1\n",
    "\n",
    "        # Display the counts on the frame\n",
    "        y_offset = 30\n",
    "        for class_name, count in class_counts.items():\n",
    "            cv2.putText(frame, f\"{class_name}: {count}\", (w-200, y_offset),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            y_offset += 30\n",
    "\n",
    "        video_writer.write(frame) # write frame to output video\n",
    "    #show the frame\n",
    "    cv2.imshow('YOLO object tracking and counting', frame)\n",
    "\n",
    "    # exit loop if 'q' id pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# release the video capture object and close all OpenCV windows\n",
    "cap.release()  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef71ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # logic - if you want to filter out persons sitting on motorbikes or bicycles.\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# def filter_pedestrians(detections):\n",
    "#     persons = [d for d in detections if d['class'] == 'person']\n",
    "#     motorbikes = [d for d in detections if d['class'] == 'motorbike']\n",
    "    \n",
    "#     pedestrians = []\n",
    "    \n",
    "#     for person in persons:\n",
    "#         person_box = person['bbox']\n",
    "#         is_pedestrian = True\n",
    "        \n",
    "#         for motorbike in motorbikes:\n",
    "#             motorbike_box = motorbike['bbox']\n",
    "            \n",
    "#             # Check if the person is sitting on the motorbike\n",
    "#             if is_person_on_motorbike(person_box, motorbike_box):\n",
    "#                 is_pedestrian = False\n",
    "#                 break\n",
    "        \n",
    "#         if is_pedestrian:\n",
    "#             pedestrians.append(person)\n",
    "    \n",
    "#     return pedestrians\n",
    "\n",
    "# def is_person_on_motorbike(person_box, motorbike_box):\n",
    "#     # Define the criteria for a person sitting on a motorbike\n",
    "#     # For simplicity, we check if the person box is within the motorbike box\n",
    "#     px, py, pw, ph = person_box\n",
    "#     mx, my, mw, mh = motorbike_box\n",
    "    \n",
    "#     if (px > mx and py > my and px + pw < mx + mw and py + ph < my + mh):\n",
    "#         return True\n",
    "#     return False\n",
    "\n",
    "# # Example detections from YOLO\n",
    "# detections = [\n",
    "#     {'class': 'person', 'bbox': [50, 50, 100, 200]},\n",
    "#     {'class': 'motorbike', 'bbox': [40, 40, 120, 220]},\n",
    "#     {'class': 'person', 'bbox': [200, 200, 100, 200]},\n",
    "# ]\n",
    "\n",
    "# pedestrians = filter_pedestrians(detections)\n",
    "# print(\"Pedestrians:\", pedestrians)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
